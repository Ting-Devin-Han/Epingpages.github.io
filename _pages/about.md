---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

# Yiping Chen (陈一平)

Yiping Chen is an **Associate Professor** / **Ph.D. Supervisor** at the [School of Geospatial Engineering and Science](https://sges.sysu.edu.cn/), [Sun Yat-sen University](https://www.sysu.edu.cn/). She is also the Deputy Director of the Science Research Institute at Sun Yat-sen University, a Senior Member of IEEE, and a Senior Member of CSIG (China Society of Image and Graphics). Her main research interests include **LiDAR remote sensing**, **intelligent processing of 3D point clouds**, **remote sensing image processing**, and **sustainable development applications**. She has led 12 projects including the National Natural Science Foundation of China and participated in over 20 projects including the Key Program of the National Natural Science Foundation of China. She has published **50+** papers in major journals and conferences, including ISPRS JPRS, CVPR, IEEE TGRS, IEEE TITS, and JAG.

<p style="color: red;">
  I am looking for self-motivated students, postdocs, research assistants, and visiting scholars! Please drop me an <a href="mailto:chenyp79@sysu.edu.cn" style="color: red; text-decoration: underline;">email📧(chenyp79@mail.sysu.edu.cn)</a> if you are interested in working with me!
</p>

## News 💥💥💥
- 2024-05-15: Yiping Chen is appointed as the **chair** of the [ISPRS WG I/4 working group](https://www2.isprs.org/commissions/comm1/wg4/)!
- 2024-04-22: The paper [Chat3D: Interactive Understanding 3D Scene-Level Point Clouds by Chatting with Foundation Model for Urban Ecological Construction](https://www.sciencedirect.com/science/article/pii/S0924271624001849) is accepted by **<font color=red>ISPRS Journal</font>**!
- 2024-03-16: The paper is accept as an **oral presentation** in the **<font color=red>IGARSS 2024</font>**!
- 2024-02-27: The paper [SPTNet: Sparse Convolution and Transformer Network for Woody and Foliage Components Separation from Point Clouds](https://ieeexplore.ieee.org/abstract/document/10466757) is accepted by **<font color=red>IEEE TGRS</font>**!
- 2024-02-24: The paper [Joint Structure Detection and Multi-Scale Clustering Filtering for Tunnel Lining Extraction From Point Clouds](https://ieeexplore.ieee.org/abstract/document/10492659) is accepted by **<font color=red>IEEE TITS</font>**!
- 2024-02-02: The paper [Low-FaceNet: Face recognition-driven low-light image enhancement](https://ieeexplore.ieee.org/abstract/document/10476748) is accepted by **<font color=red>IEEE TIM</font>**!
- 2024-01-18: The paper [A Survey of Point Cloud Completion](https://ieeexplore.ieee.org/abstract/document/10433645) is accepted by **<font color=red>IEEE JSTARS</font>**!

## Representative Publication 🔥🔥🔥
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/Chat3D.jpg" alt="Chat3D" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>Chat3D: Interactive Understanding 3D Scene-Level Point Clouds by Chatting with Foundation Model for Urban Ecological Construction</strong><br>
    <strong>Yiping Chen</strong>, Shuai Zhang, Ting Han, Yumeng Du, Wuming Zhang, Jonathan Li<br>
    ISPRS Journal of Photogrammetry and Remote Sensing 2024 (<strong>IF=12.7</strong>)<br>
    <a href="https://www.sciencedirect.com/science/article/pii/S0924271624001849">Paper📄</a>
  </div>
</div>
<br>
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/SPTNet.png" alt="SPTNet" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>SPTNet: Sparse Convolution and Transformer Network for Woody and Foliage Components Separation from Point Clouds</strong><br>
    Shuai Zhang, <strong>Yiping Chen*</strong>, Biao Wang, Dong Pan, Wuming Zhang, Aiguang Li<br>
    IEEE Transactions on Geoscience and Remote Sensing 2024 (<strong>IF=8.2, CCF-B</strong>)<br>
    <a href="https://ieeexplore.ieee.org/abstract/document/10466757">Paper📄</a>
  </div>
</div>
<br>
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/ClickWentaoSun.png" alt="ClickWentaoSun" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>A Click-based Interactive Segmentation Network for Point Clouds</strong><br>
    Wentao Sun, Zhipeng Luo, <strong>Yiping Chen*</strong>, Huxiong Li, Jose Marcato, Wesley Nunes Gonçalves, Jonathan Li*<br>
    IEEE Transactions on Geoscience and Remote Sensing 2023 (<strong>IF=8.2, CCF-B</strong>)<br>
    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10285459">Paper📄</a>
  </div>
</div>
<br>
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/RoadsideLinaFang.png" alt="RoadsideLinaFang" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>A Joint Deep Learning Network of Point Clouds and Multiple Views for Roadside Object Classification from LiDAR Point Clouds</strong><br>
    Lina Fang, Zhilong You, Guixi Shen, <strong>Yiping Chen*</strong>, Jianrong Li<br>
    ISPRS Journal of Photogrammetry and Remote Sensing 2022 (<strong>IF=12.7</strong>)<br>
    <a href="https://www.sciencedirect.com/science/article/pii/S0924271622002313">Paper📄</a>
  </div>
</div>
<br>
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/DBNet.gif" alt="DBNet" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>LiDAR-Video Driving Dataset: Learning Driving Policies Effectively</strong><br>
    <strong>Yiping Chen</strong>, Jingkang Wang, Jonathan Li, Cewu Lu, Zhipeng Luo, Han Xue, Cheng Wang<br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR) 2018 (<strong>CCF-A</strong>)<br>
    <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.html">Paper📄</a>|
    <a href="https://github.com/driving-behavior/DBNet">Code💻</a>|
    <a href="http://www.dbehavior.net/">HomePage🏠</a>
  </div>
</div>

## Open Source Dtaset 🔍🔍🔍
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/JMC.gif" alt="JMC" style="width: 90%;"/>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/CAR.gif" alt="CAR" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>City-Facade</strong> is a large-scale urban building facade dataset for semantic-level and instance-level segmentation from MLS LiDAR point clouds. It consists of labeled point clouds (with 9 classes for building facades) as well as unlabeled data (point clouds of street landscapes). The data collection area encompasses a variety of streets in Xiamen, China, with distinct architectural styles. We believe that our City-Facade will faciliate feature research on point cloud semantic or instance segmentation, urban understanding and modeling, point cloud completion, etc. Welcome to download and make use of City-Facade.<br>
    <!-- <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.html">Paper📄</a>| -->
    <a href="https://github.com/Ting-Devin-Han/City-Facade">Code💻</a>
    <!-- <a href="http://www.dbehavior.net/">HomePage🏠</a> -->
  </div>
</div>
<br>
<div style="display: flex; align-items: center; width: 100%;">
  <div style="flex: 30%;">
    <a>
        <img src="https://github.com/Ting-Devin-Han/Epingpages.github.io/raw/master/images/DBNet.gif" alt="DBNet" style="width: 90%;"/>
    </a>
  </div>
  <div style="flex: 70%;">
    <strong>DBNet</strong> is a comprehensive large-scale dataset that includes 3D point cloud data, video images, GNSS data, and driver behavior metrics such as speed and direction. It Covers over 1,000 kilometres in Xiamen with different types of roads. DBNet provides city-level 3D point cloud with coresponding 2D video images, serving as a robust foundation for decision-making in autonomous driving. It has been widely used by more than 600 organizations and individuals across the world, including MIT, Google, etc. Welcome to download and make use of DBNet.<br>
    <a href="https://openaccess.thecvf.com/content_cvpr_2018/html/Chen_LiDAR-Video_Driving_Dataset_CVPR_2018_paper.html">Paper📄</a>|
    <a href="https://github.com/driving-behavior/DBNet">Code💻</a>|
    <a href="http://www.dbehavior.net/">HomePage🏠</a>
  </div>
</div>
<br>


